{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb55342",
   "metadata": {},
   "source": [
    "# Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f48ce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "  LIPIDOMICS ANNOTATION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "Input file: /Users/bowen/Desktop/deep_lipid_v1/worms/feature_df.csv\n",
      "Result directory: result/result_pipeline_test\n",
      "Database: dataset/lipid_plus.db\n",
      "\n",
      "================================================================================\n",
      "  STEP 0: PROCESS MS2 DATA\n",
      "================================================================================\n",
      "\n",
      "‚Üí Running: python code/process_ms2.py /Users/bowen/Desktop/deep_lipid_v1/worms/feature_df.csv --output_path result/result_pipeline_test/processed_feature_table.csv --neutral_loss --decimal_point 0\n",
      "Starting processing with decimal_point=0, neutral_loss=True, keep_intensity=False...\n",
      "Processing complete.\n",
      "Saved processed file to result/result_pipeline_test/processed_feature_table.csv\n",
      "\n",
      "‚úì Step 0 complete: MS2 data processed and saved to processed_feature_table.csv\n",
      "\n",
      "================================================================================\n",
      "  STEP 1: DATABASE SEARCH\n",
      "================================================================================\n",
      "\n",
      "‚Üí Running: python code/db_search.py result/result_pipeline_test/processed_feature_table.csv --result_path result/result_pipeline_test --db_path dataset/lipid_plus.db --MS1_tol 0.005 --MS2_tol 0.01 --MS2_threshold 0.7 --is_ppm False\n",
      "Compile the cython code is highly recommended!\n",
      "Loading data from 'result/result_pipeline_test/processed_feature_table.csv'...\n",
      "Normalizing MS2 spectra...\n",
      "Normalization complete.\n",
      "Starting database search...\n",
      "Database Searching: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1063/1063 [04:43<00:00,  3.75it/s]\n",
      "Database search finished.\n",
      "Saving results to 'result/result_pipeline_test'...\n",
      "Annotated data saved to: result/result_pipeline_test/db_matched_df.csv\n",
      "Dark lipid data saved to: result/result_pipeline_test/dark_lipid.csv\n",
      "\n",
      "--- Summary ---\n",
      "Total spectra: 1063\n",
      "Annotated spectra: 140 (13.17%)\n",
      "Unknown spectra: 923 (86.83%)\n",
      "---------------\n",
      "\n",
      "\n",
      "‚úì Step 1 complete: 923 unknown lipids to process\n",
      "\n",
      "================================================================================\n",
      "  STEP 2: ADDUCT PREDICTION\n",
      "================================================================================\n",
      "\n",
      "‚Üí Running: python code/adduct_predict.py result/result_pipeline_test/dark_lipid.csv model/adduct.joblib --output_path result/result_pipeline_test/adduct_predictions.csv\n",
      "======================================================================\n",
      "ADDUCT PREDICTION\n",
      "======================================================================\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/pickle.py:1760: UserWarning: [16:23:24] WARNING: /Users/runner/work/xgboost/xgboost/src/gbm/../common/error_msg.h:83: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  setstate(state)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "‚úì Model loaded successfully from: model/adduct.joblib\n",
      "  Model type: XGBoost\n",
      "  Validation Accuracy: 0.9962\n",
      "  Test Accuracy: 0.9964\n",
      "\n",
      "Loading input data from: result/result_pipeline_test/dark_lipid.csv\n",
      "‚úì Data loaded successfully\n",
      "  Number of samples: 923\n",
      "\n",
      "Preparing features...\n",
      "‚úì Features prepared\n",
      "  Number of features: 1453\n",
      "\n",
      "Making predictions...\n",
      "‚úì Predictions completed\n",
      "  Average confidence: 0.8211\n",
      "\n",
      "Saving results to: result/result_pipeline_test/adduct_predictions.csv\n",
      "‚úì Results saved successfully\n",
      "\n",
      "======================================================================\n",
      "PREDICTION SUMMARY\n",
      "======================================================================\n",
      "Total predictions: 923\n",
      "\n",
      "Predicted adduct distribution:\n",
      "predicted_adduct\n",
      "[M-H]-         304\n",
      "[M+Na]+        267\n",
      "[M+NH4]+       173\n",
      "[M+H]+         158\n",
      "[M]+            10\n",
      "[M+HCOO]-       10\n",
      "[M+CH3COO]-      1\n",
      "======================================================================\n",
      "\n",
      "‚úì Prediction completed successfully!\n",
      "\n",
      "‚úì Step 2 complete: Adducts predicted\n",
      "\n",
      "================================================================================\n",
      "  STEP 3: CLASS PREDICTION\n",
      "================================================================================\n",
      "\n",
      "‚Üí Running: python code/class_predict.py result/result_pipeline_test/adduct_predictions.csv model/class.joblib --output_path result/result_pipeline_test/class_predictions.csv --ms1_tol 10.0 --ms2_tol 20.0\n",
      "======================================================================\n",
      "CLASS PREDICTION (HYBRID: RULE-BASED + ML)\n",
      "======================================================================\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/pickle.py:1760: UserWarning: [16:23:27] WARNING: /Users/runner/work/xgboost/xgboost/src/gbm/../common/error_msg.h:83: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  setstate(state)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "‚úì Model loaded successfully from: model/class.joblib\n",
      "  Model type: XGBoost\n",
      "\n",
      "Loading input data from: result/result_pipeline_test/adduct_predictions.csv\n",
      "‚úì Data loaded successfully\n",
      "  Number of samples: 923\n",
      "\n",
      "--- Applying rule-based classification ---\n",
      "  MS1 tolerance: 10.0 ppm\n",
      "  MS2 tolerance: 0.01 Da\n",
      "  Step 1: Identifying classes by precursor mass...\n",
      "  Step 2: Identifying classes by MS2 fragments...\n",
      "  Step 3: Finding overlap for final class...\n",
      "  Step 4: Adding category...\n",
      "‚úì Rule-based classification complete\n",
      "  Successfully classified: 230 / 923 rows\n",
      "\n",
      "--- Applying ML model for 693 remaining rows ---\n",
      "\n",
      "Preparing features for ML model...\n",
      "  Using 'adduct' column for prediction\n",
      "‚úì Features prepared\n",
      "  Number of features: 1454\n",
      "\n",
      "Making ML predictions...\n",
      "‚úì ML predictions completed\n",
      "  Average ML confidence: 0.6895 (excluding unknowns)\n",
      "Processing metadata (Category, Chain info)...\n",
      "  Using 'predicted_class' for metadata\n",
      "‚úì Category and chain information added\n",
      "\n",
      "Saving results to: result/result_pipeline_test/class_predictions.csv\n",
      "‚úì Results saved successfully\n",
      "\n",
      "======================================================================\n",
      "PREDICTION SUMMARY\n",
      "======================================================================\n",
      "Total predictions: 923\n",
      "\n",
      "Prediction sources:\n",
      "prediction_source\n",
      "model-based    693\n",
      "rule-based     230\n",
      "\n",
      "Rule-based predictions: 230\n",
      "ML-based predictions: 693\n",
      "\n",
      "Predicted class distribution:\n",
      "predicted_class\n",
      "FA                                      240\n",
      "PC                                      123\n",
      "LPC                                      81\n",
      "PE-O                                     79\n",
      "PE                                       73\n",
      "MG                                       49\n",
      "DG                                       43\n",
      "TG                                       38\n",
      "Adduct '[M+H-H2O]+' not recognized.      35\n",
      "NAE                                      28\n",
      "MGDG                                     16\n",
      "CE                                       15\n",
      "PG                                       15\n",
      "Adduct '[M-2H]2-' not recognized.        12\n",
      "PA                                       12\n",
      "PI                                       11\n",
      "PS                                       11\n",
      "LPE                                       7\n",
      "LPE-P                                     7\n",
      "LPC-P                                     6\n",
      "LPC-O                                     6\n",
      "PC-O                                      4\n",
      "DGDG                                      2\n",
      "DGTS                                      2\n",
      "CL                                        2\n",
      "Adduct '[M+2Na-H]+' not recognized.       1\n",
      "BMP                                       1\n",
      "Adduct '[M-H2O-H]-' not recognized.       1\n",
      "Adduct '[2M-H]-' not recognized.          1\n",
      "Adduct '[M+H-2H2O]+' not recognized.      1\n",
      "Adduct '[M+Na-2H]-' not recognized.       1\n",
      "\n",
      "Category distribution:\n",
      "category\n",
      "GP         438\n",
      "FA         268\n",
      "GL         148\n",
      "Unknown     52\n",
      "ST          15\n",
      "SL           2\n",
      "======================================================================\n",
      "\n",
      "‚úì Step 3 complete: Classes predicted\n",
      "\n",
      "================================================================================\n",
      "  STEP 4: CHAIN COMPOSITION PREDICTION (PLSF)\n",
      "================================================================================\n",
      "\n",
      "‚Üí Running: python code/predict_plsf.py model/plsf.joblib result/result_pipeline_test/class_predictions.csv --output_path result/result_pipeline_test/final_annotations.csv\n",
      "Loading model from model/plsf.joblib...\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/pickle.py:1760: UserWarning: [16:23:31] WARNING: /Users/runner/work/xgboost/xgboost/src/gbm/../common/error_msg.h:83: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  setstate(state)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "‚úì Loaded model: XGBoost (Split by Chain) Top-5\n",
      "  Mode: Split by Chain\n",
      "Loading data from result/result_pipeline_test/class_predictions.csv...\n",
      "  Samples: 923\n",
      "  Features: 1451 mz_ columns\n",
      "Preparing data...\n",
      "  Note: Using 'predicted_class' for missing 'class' column\n",
      "  Warning: Unknown values in 'adduct': {'[M-H2O-H]-', '[M+Na-2H]-', '[M+H-2H2O]+', '[M-2H]2-', '[M+2Na-H]+'}\n",
      "  Rows with these values will have empty predictions\n",
      "  Warning: Unknown values in 'class': {\"Adduct '[2M-H]-' not recognized.\", \"Adduct '[M+H-2H2O]+' not recognized.\", 'LPC-P', \"Adduct '[M-H2O-H]-' not recognized.\", \"Adduct '[M+Na-2H]-' not recognized.\", \"Adduct '[M+2Na-H]+' not recognized.\", \"Adduct '[M+H-H2O]+' not recognized.\", 'LPE-P', \"Adduct '[M-2H]2-' not recognized.\"}\n",
      "  Rows with these values will have empty predictions\n",
      "Making predictions...\n",
      "  Note: Cleared predictions for 65 rows with unknown adduct/class               \n",
      "‚úì Predictions complete\n",
      "\n",
      "Formatting output columns...\n",
      "Saving predictions to result/result_pipeline_test/final_annotations.csv...\n",
      "‚úì Saved 923 predictions\n",
      "\n",
      "Prediction Summary:\n",
      "  Total C range: 2.0-88.0\n",
      "  Total DB range: 0.0-18.0\n",
      "  Pred Confidence: mean=0.649, min=0.290, max=0.980\n",
      "  num_chain distribution:\n",
      "    1.0: 426 samples (46.2%)\n",
      "    2.0: 392 samples (42.5%)\n",
      "    3.0: 38 samples (4.1%)\n",
      "    4.0: 2 samples (0.2%)\n",
      "\n",
      "‚úì Success!\n",
      "\n",
      "‚úì Step 4 complete: Chain compositions predicted\n",
      "\n",
      "================================================================================\n",
      "  MERGING AND PROCESSING RESULTS\n",
      "================================================================================\n",
      "‚úì Loaded 923 predicted lipids\n",
      "‚úì Loaded 140 database-annotated lipids\n",
      "  Initial combined count: 1063\n",
      "‚úì Updated chain_info for 105 rows (conf > 0.8, empty chain_info, valid plsf_rank1)\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "/Users/bowen/Desktop/lipid_plus_v2/run.py:428: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df.loc[adduct_mask, existing_clear_cols] = \"\"\n",
      "‚úì Cleared 23 columns for 52 rows where name starts with 'Adduct'\n",
      "‚úì Dropped 1459 columns (mz_* and internal prediction cols)\n",
      "\n",
      "‚úì Processed results saved to: identification_result.csv\n",
      "  Final shape: (1063, 41)\n",
      "\n",
      "================================================================================\n",
      "  POST-PROCESSING RESULTS\n",
      "================================================================================\n",
      "‚úì Loaded 1063 rows from identification_result.csv\n",
      "‚úì Rule 3 applied: Updated chain_info for 12 rows (conf > 0.8 & empty chain_info)\n",
      "‚úì Post-processed results saved to: identification_result.csv\n",
      "\n",
      "================================================================================\n",
      "  ANNOTATION STATISTICS\n",
      "================================================================================\n",
      "\n",
      "üìä TOTAL FEATURES: 1063\n",
      "\n",
      "üîç DATABASE SEARCH RESULTS:\n",
      "   ‚Ä¢ Number of matches: 140\n",
      "   ‚Ä¢ Method: Spectral similarity matching\n",
      "   ‚Ä¢ MS1 tolerance: 0.005 Da\n",
      "   ‚Ä¢ MS2 tolerance: 0.01 Da\n",
      "   ‚Ä¢ MS2 similarity threshold: 0.7\n",
      "\n",
      "‚≠ê TIER 1 PREDICTIONS (High Confidence):\n",
      "   ‚Ä¢ Number of features: 117\n",
      "   ‚Ä¢ Confidence threshold: > 0.8\n",
      "   ‚Ä¢ Average confidence: 0.865\n",
      "\n",
      "üìù TIER 2 ANNOTATIONS (All identified features):\n",
      "   ‚Ä¢ Number of features: 1011\n",
      "   ‚Ä¢ Percentage of total: 95.1%\n",
      "\n",
      "üìã ANNOTATION SOURCE BREAKDOWN:\n",
      "   ‚Ä¢ Database matched: 140\n",
      "   ‚Ä¢ ML predicted: 871\n",
      "   ‚Ä¢ Unidentified: 52\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "  CLEANING UP INTERMEDIATE FILES\n",
      "================================================================================\n",
      "‚Üí Moved processed_feature_table.csv to process_files/\n",
      "‚Üí Moved adduct_predictions.csv to process_files/\n",
      "‚Üí Moved db_matched_df.csv to process_files/\n",
      "‚Üí Moved final_annotations.csv to process_files/\n",
      "‚Üí Moved class_predictions.csv to process_files/\n",
      "‚Üí Moved dark_lipid.csv to process_files/\n",
      "\n",
      "‚úì Cleanup complete. 6 files moved to process_files/.\n",
      "\n",
      "================================================================================\n",
      "  PIPELINE COMPLETE\n",
      "================================================================================\n",
      "\n",
      "All results saved to: result/result_pipeline_test\n",
      "Final output: result/result_pipeline_test/identification_result.csv\n",
      "\n",
      "‚úì Success!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python run.py /Users/bowen/Desktop/deep_lipid_v1/worms/feature_df.csv --result_path result/result_pipeline_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd2dcaa",
   "metadata": {},
   "source": [
    "# Advanced Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20816bd",
   "metadata": {},
   "source": [
    "## DB search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83561bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing with decimal_point=0, neutral_loss=True, keep_intensity=False...\n",
      "Processing complete.\n",
      "Saved processed file to result/test_adv/input.csv\n",
      "Compile the cython code is highly recommended!\n",
      "Loading data from 'result/test_adv/input.csv'...\n",
      "Normalizing MS2 spectra...\n",
      "Normalization complete.\n",
      "Starting database search...\n",
      "Annotating spectra:   4%|‚ñâ                     | 22/500 [00:11<04:00,  1.99it/s]^C\n"
     ]
    }
   ],
   "source": [
    "! python code/process_ms2.py result/test_adv/demo.csv --output_path result/test_adv/input.csv\n",
    "! python code/db_search.py result/test_adv/input.csv --result_path result/test_adv/annotation.csv --db_path dataset/lipid_plus.db "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1ee47",
   "metadata": {},
   "source": [
    "## Adduct (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6cfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing with decimal_point=0, neutral_loss=True, keep_intensity=False...\n",
      "Processing complete.\n",
      "Saved processed file to result/test_adv/input.csv\n",
      "‚úó Error: Input file not found: rresult/test_adv/input.csv\n"
     ]
    }
   ],
   "source": [
    "! python code/process_ms2.py result/test_adv/demo.csv --output_path result/test_adv/input.csv\n",
    "! python code/adduct_predict.py rresult/test_adv/input.csv model/adduct.joblib --output_path result/test_adv/pred_adduct.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566ed0fb",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8206934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing with decimal_point=0, neutral_loss=True, keep_intensity=False...\n",
      "Processing complete.\n",
      "Saved processed file to result/test_adv/input.csv\n",
      "======================================================================\n",
      "CLASS PREDICTION (HYBRID: RULE-BASED + ML)\n",
      "======================================================================\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/pickle.py:1760: UserWarning: [16:17:52] WARNING: /Users/runner/work/xgboost/xgboost/src/gbm/../common/error_msg.h:83: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  setstate(state)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "‚úì Model loaded successfully from: model/class.joblib\n",
      "  Model type: XGBoost\n",
      "\n",
      "Loading input data from: result/test_adv/input.csv\n",
      "‚úì Data loaded successfully\n",
      "  Number of samples: 500\n",
      "\n",
      "--- Applying ML model for 500 remaining rows ---\n",
      "\n",
      "Preparing features for ML model...\n",
      "  Using 'adduct' column for prediction\n",
      "‚úì Features prepared\n",
      "  Number of features: 1454\n",
      "\n",
      "Making ML predictions...\n",
      "‚úì ML predictions completed\n",
      "  Average ML confidence: 0.9830 (excluding unknowns)\n",
      "Processing metadata (Category, Chain info)...\n",
      "  Using 'predicted_class' for metadata\n",
      "‚úì Category and chain information added\n",
      "\n",
      "Saving results to: result/test_adv/pred_class.csv\n",
      "‚úì Results saved successfully\n",
      "\n",
      "======================================================================\n",
      "PREDICTION SUMMARY\n",
      "======================================================================\n",
      "Total predictions: 500\n",
      "\n",
      "Prediction sources:\n",
      "prediction_source\n",
      "model-based    500\n",
      "ML-based predictions: 500\n",
      "\n",
      "Predicted class distribution:\n",
      "predicted_class\n",
      "TG       292\n",
      "PC        53\n",
      "PE        38\n",
      "PE-O      19\n",
      "DG        18\n",
      "MGDG      12\n",
      "DGCC      12\n",
      "PC-O      11\n",
      "DGGA       8\n",
      "PS         6\n",
      "BMP        5\n",
      "DGTS       4\n",
      "SQDG       4\n",
      "FA         3\n",
      "PI         3\n",
      "DGDG       3\n",
      "PG         2\n",
      "LPC        2\n",
      "PA         2\n",
      "PMeOH      1\n",
      "LPE-O      1\n",
      "SM         1\n",
      "\n",
      "Category distribution:\n",
      "category\n",
      "GL    329\n",
      "GP    143\n",
      "SL     24\n",
      "FA      3\n",
      "SP      1\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "! python code/process_ms2.py result/test_adv/demo.csv --output_path result/test_adv/input.csv\n",
    "! python code/class_predict.py result/test_adv/input.csv model/class.joblib --output_path result/test_adv/pred_class.csv --no-rules "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d0f4e",
   "metadata": {},
   "source": [
    "## PLSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b56d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from model/plsf.joblib...\n",
      "‚úì Loaded model: XGBoost (Split by Chain) Top-5\n",
      "  Mode: Split by Chain\n",
      "Loading data from result/test_adv/pred_class.csv...\n",
      "  Samples: 500\n",
      "  Features: 1451 mz_ columns\n",
      "Preparing data...\n",
      "  Note: Using 'predicted_class' for missing 'class' column\n",
      "Making predictions...\n",
      "‚úì Predictions complete                                                          \n",
      "\n",
      "Formatting output columns...\n",
      "Saving predictions to result/test_adv/pred_plsf.csv...\n",
      "‚úì Saved 500 predictions\n",
      "\n",
      "Prediction Summary:\n",
      "  Total C range: 2.0-86.0\n",
      "  Total DB range: 0.0-18.0\n",
      "  Pred Confidence: mean=0.711, min=0.250, max=0.990\n",
      "  num_chain distribution:\n",
      "    1: 6 samples (1.2%)\n",
      "    2: 202 samples (40.4%)\n",
      "    3: 292 samples (58.4%)\n",
      "\n",
      "‚úì Success!\n"
     ]
    }
   ],
   "source": [
    "! python code/predict_plsf.py model/plsf.joblib result/test_adv/pred_class.csv --output_path result/test_adv/pred_plsf.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b59446",
   "metadata": {},
   "source": [
    "## Formula (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d652a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python code/process_ms2.py result/test_adv/demo.csv --output_path result/test_adv/input.csv\n",
    "! python code/formula_annotation.py result/test_adv/input.csv --output_path result/test_adv --ms1_tol 10 --ms2_tol 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
